{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Functions to get, load, clean, split and pickle data.\n",
    "#\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import wget\n",
    "\n",
    "#\n",
    "# Get data\n",
    "#\n",
    "\n",
    "def get_data(dl_urls, data_dir):\n",
    "    '''Download data files in csv format.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dl_urls : dict of str: str\n",
    "        Dictionary of destination filenames and URLs that point directly\n",
    "        to data files to be downloaded.\n",
    "    data_dir : str\n",
    "        Location of destination directory for downloaded data files.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        Data Frame that displays the file name and file size of\n",
    "        downloaded data files.\n",
    "    '''\n",
    "    report = {}\n",
    "    for f, url in dl_urls.items():\n",
    "        path = os.path.join(data_dir, f)\n",
    "        if not os.path.isfile(path):\n",
    "            if not os.path.isdir(data_dir):\n",
    "                os.mkdir(data_dir)\n",
    "            try:\n",
    "                wget.download(url=url, out=path)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                raise\n",
    "        file_size_mb = round(os.path.getsize(path) / (1024**2), 2)\n",
    "        report[f] = file_size_mb\n",
    "        df = pd.DataFrame.from_dict(report, orient='index',\n",
    "                                    columns=['File Size in MB'])\n",
    "    return df\n",
    "\n",
    "#\n",
    "# Load data\n",
    "#\n",
    "\n",
    "def read_data(data_title, data_dir, data_file):\n",
    "    '''Read data from CSV or GEOJSON files into data frames.\n",
    "    \n",
    "    Output dtypes, non-null values and memory usage information on data\n",
    "    frames. Store dataframe memory usage for comparison later.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_title : str\n",
    "        Brief title that describes the nature of the data.\n",
    "    data_file : str\n",
    "        File name of data file.\n",
    "    data_dir : str\n",
    "        Directory where data files are located.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame or GeoDataFrame\n",
    "        DataFrame of CSV data or GeoDataFrame of GEOJSON data.\n",
    "    '''\n",
    "    ext = data_file.split(\".\")[-1].lower()\n",
    "    file_path = os.path.join(data_dir, data_file)\n",
    "    if ext == 'csv':\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=',', header=0)\n",
    "        except IOError as e:\n",
    "            print(e)\n",
    "            raise\n",
    "    elif ext == 'pkl':\n",
    "        try:\n",
    "            df = pd.read_pickle(file_path)\n",
    "        except IOError as e:\n",
    "            print(e)\n",
    "            raise\n",
    "    else:\n",
    "        raise Exception('Data file extension `{}` is the incorrect file type. '\n",
    "                        'Use .csv and .pkl files only.'.format(ext))\n",
    "    df.columns = (df\n",
    "                  .columns\n",
    "                  .str.strip()\n",
    "                  .str.lower()\n",
    "                  .str.replace(' ', '_'))\n",
    "    print('{}'.format(data_title))\n",
    "    print(df.info(memory_usage='deep'))\n",
    "    print('\\n')\n",
    "    \n",
    "    return df\n",
    "\n",
    "#\n",
    "# Clean data\n",
    "#\n",
    "\n",
    "def sample_size(df):\n",
    "    '''Limit the number of observations to display using the sample\n",
    "    method.\n",
    "    \n",
    "    If the number of samples to display is more than the number of rows\n",
    "    in the data frame, an error will occur.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Data Frame that samples will be drawn from.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sample: int\n",
    "        The number of samples to display.\n",
    "    '''\n",
    "    if df.shape[0] < 3:\n",
    "        sample = df.shape[0]\n",
    "    else:\n",
    "        sample = 3\n",
    "    return sample\n",
    "\n",
    "def review_data(df):\n",
    "    '''Pretty print the data frame head, tail, samples and nulls.\n",
    "    \n",
    "    Relies on the IPython.display setting in the Settings sections to\n",
    "    pretty print all data frames, not just the last data frame in a\n",
    "    Jupyter cell.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Data Frame that will be displayed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    sample = sample_size(df)\n",
    "\n",
    "    display(df.head(sample))\n",
    "    display(df.tail(sample))\n",
    "    display(df.sample(sample))\n",
    "    df_null = df.isnull().sum().to_frame(name='is_null')\n",
    "    display(df_null)\n",
    "\n",
    "def memory_usage(df):\n",
    "    '''Return memory usage of data frame in megabytes (MB).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Data Frame that will be analyzed for memory usage.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float that holds the memory usage of the data frame in megabytes\n",
    "    (MB).\n",
    "    '''\n",
    "    return round(df.memory_usage(deep=True).sum() / (1024**2), 2)\n",
    "\n",
    "def optimize_df(df, cols_convert, cols_order=None):\n",
    "    '''Convert columns to optimal data type and display memory usage.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Data Frame that will be optimized.\n",
    "    cols_convert : dict of str: data type\n",
    "        Dictionary of columns names as keys and data types as values.\n",
    "    cols_order : list of str, optional\n",
    "        Ordered list of column names to reorder columns in data frame.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    print(df.info(memory_usage='deep'))\n",
    "    mem_before = memory_usage(df)\n",
    "    for col, dtype in cols_convert.items():\n",
    "        df[col] = df[col].astype(dtype)\n",
    "    if cols_order:\n",
    "        df = df[cols_order]\n",
    "    mem_after = memory_usage(df)\n",
    "    \n",
    "    print(df.info(memory_usage='deep'))\n",
    "    print('*' * 20)\n",
    "    print('Memory usage before: {} MB'.format(mem_before))\n",
    "    print('Memory usage after: {} MB'.format(mem_after))\n",
    "    \n",
    "    sample = sample_size(df)\n",
    "    display(df.sample(sample))\n",
    "\n",
    "#\n",
    "# Split data\n",
    "#\n",
    "\n",
    "def split_train_test(df, col, no_dupe, date_lt='2017-11-01',\n",
    "                     date_gt='2017-10-01'):\n",
    "    '''Split datset into training and test sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Data Frame of raw values that will be grouped into counts.\n",
    "    col : str\n",
    "        Datetime column name for either opened or closed requests.\n",
    "    no_dupe : boolean\n",
    "        Specifies whether or not to exclude duplicated Service Request\n",
    "        Numbers.\n",
    "    date_lt : str\n",
    "        Cut off date for training set.\n",
    "    date_gt : str\n",
    "        Cut off date for test set.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_train : pd.DataFrame\n",
    "        Data Frame of data points for training set.\n",
    "    df_test : pd.DataFrame\n",
    "        Data Frame of data points for test set.\n",
    "    '''\n",
    "    mask = df[col].notnull()\n",
    "    if no_dupe:\n",
    "        mask = (mask) & ~(df['is_duplicate'])\n",
    "    df_ct = (df[mask]\n",
    "             .set_index(col)\n",
    "             .resample('MS')\n",
    "             .size()\n",
    "             .to_frame('count'))\n",
    "    # Drop any dates after October 2018\n",
    "    date_cutoff = '2018-11-01'\n",
    "    df_train = df_ct[(df_ct.index < date_lt) \n",
    "                     & (df_ct.index < date_cutoff)].copy()\n",
    "    df_test = df_ct[(df_ct.index > date_gt) \n",
    "                    & (df_ct.index < date_cutoff)].copy()\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "#\n",
    "# Pickle data\n",
    "#\n",
    "\n",
    "def export_pickle(filename, df, data_dir):\n",
    "    '''Pickle data frames to preserve attributes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Filename for output file.\n",
    "    df : DataFrame or GeoDataFrame\n",
    "        DataFrame or GeoDataFrame to be pickled.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    pkl_file = os.path.join(data_dir, '{}.pkl'.format(filename))\n",
    "    df.to_pickle(pkl_file)\n",
    "    print('{}: {}'.format(filename, df.shape))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
